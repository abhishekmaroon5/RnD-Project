# -*- coding: utf-8 -*-
"""Code_CNN_From_Scratch_and_using_VGG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14RRDFqWaIK01m3WVXIO4-_pATaMCPWui
"""

import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Dropout, Flatten, Dense
from keras import applications
from keras.regularizers import l2
from keras import optimizers

from keras.models import Sequential
! git clone --recursive https://github.com/abhishekmaroon5/dataset2

# dimensions of our images.
img_width, img_height = 224, 224
top_model_weights_path = 'fc_model.h5'
num_classes = 3
model_name = 'lane_model2.h5'
train_data_dir = 'data/train'
validation_data_dir = 'data/validate'
# validation_data_dir2 = '../data2/validation4'
nb_train_samples = 1072
nb_train_helmet = 550
nb_train_nonhelmet = 522
nb_validation_samples = 224
nb_val_helmet = 119
nb_val_nonhelmet = 105
epochs = 20
batch_size = 1

cd dataset2/

datagen = ImageDataGenerator(rescale=1. / 255)
model = applications.VGG16(include_top=True, weights='imagenet',input_shape = (img_width,img_height,3))

def train_top_model():
    
    # build the VGG16 network
    
    print("Model Loaded!!!")
    last_layer = model.get_layer('block5_pool').output
    x= Flatten(name='flatten')(last_layer)
#     x = Dense(256, activation='relu', name='fc1')(x)
#     x = Dense(1, activation='sigmoid', name='fc2')(x)
    x = Dense(128, activation='relu', name='fc1')(x)
    x = Dense(128, activation='relu', name='fc2')(x)
    out = Dense(num_classes, activation='softmax', name='output')(x)
    custom_vgg_model = Model(model.input, out)
    print(custom_vgg_model.summary())

    for layer in custom_vgg_model.layers[:-3]:
             layer.trainable = False

    custom_vgg_model.layers[3].trainable

    custom_vgg_model.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])

    test_generator = datagen.flow_from_directory(
        validation_data_dir,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='binary', shuffle=True)
    #bottleneck_features_validation = base_model.predict_generator(generator, nb_validation_samples // batch_size_val)
    #np.save(open('lane_bottleneck_features_validation.npy', 'wb'),bottleneck_features_validation)
    #np.save(open('validation_files.txt', 'wb'),generator.filenames)
    '''f = open('validation_files.txt','w')
    lst = generator.filenames
    for j in range(0,len(lst)):
      f.write(str(lst[j])+"\n")
    f.close()'''

    train_generator = datagen.flow_from_directory(
        train_data_dir,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='binary',shuffle=True)

    #train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))

    #validation_labels = np.array([0] * (nb_validation_samples_correct) + [1] * (nb_validation_samples_wrong))

#     '''model.fit(train_data, train_labels,
#               epochs=epochs,
#               batch_size=batch_size_train,
#               validation_data=(validation_data, validation_labels))'''
    custom_vgg_model.fit_generator(train_generator, epochs = epochs, steps_per_epoch = nb_train_samples//batch_size, validation_data = test_generator, validation_steps = nb_validation_samples//batch_size)
    custom_vgg_model.save(model_name)

#save_bottlebeck_features()
train_top_model()



